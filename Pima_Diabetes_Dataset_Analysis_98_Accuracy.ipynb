{
  "cells": [
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'pimadiabetescsv:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F945344%2F1601678%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240911%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240911T051900Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3Db3d57b5b4474ee71bd32264ed5eb0fcf4fb79df2c3079ae204588ca137c977e5d59680afa1b5be3faed348983e31a749534b7992402ca5bd062161065a85bc9faaf6dc05a5aa7a1177163eada512b746f3824263e36d8d45264d2debf02da2562b678c0a14c11ab42acced3ed55c8ea6e8ef8e6950af018c7656dace653c5b10a94976c46f65b21d549d9488a98300d6f0596b165132baadc317eae4ef0ad062cdbf3c4e5ecab17bc18f39edb6352395d5154a9b07c33405fc40bb5a5644952309cc5b521dad78dd650692a4358993b9da6072b91340a93df9412be5839ddf35900806a9874db55fece45de64ef05d29f3644c1c28a28653baf523119dd25c6b,multiples:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F993686%2F1678469%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240911%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240911T051900Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D634296d3f670d082bbafb68afb10cf6a19601e180168aa9f8aff2799276e72287074715a60364e01313da85ef25ae99a1db33aa2c7e05420d48e8873c54fd6cf9b8e9fb04f98708a2d5973dbd1986a71ff996f1257cfba4993f398b32eff419d7b4cd270036f931b4e7a079dcd3a98f7638e9cabb0b97a4fd7f4f4e73256b3e83ef172a8a0701bbe9c7eff14bad6e4a057a8267f5a4a9b9b0577caabc13d182ff6e0e00235bbd3bbe233da6f76e1dde621c826310e5ec38fd12cae9d52bad055afef05f3184597c94984709e66b2ff75c9d3a1e1c1dc29cf1123670f1e89bdd99a5f9f2624bdf02d8453547df6b1af40f79dba0e8ef49d96c7be5a51ec74fce2'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "zAXRpVgGhV12"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "papermill": {
          "duration": 0.020628,
          "end_time": "2020-11-26T03:01:57.53503",
          "exception": false,
          "start_time": "2020-11-26T03:01:57.514402",
          "status": "completed"
        },
        "tags": [],
        "id": "1RMYs4Y2hV1-"
      },
      "cell_type": "markdown",
      "source": [
        "# Pima Diabetes Dataset Analysis (98% Accuracy & 98% F1 Score)\n",
        "\n",
        "### Using Keras(Dense Layer), Optuna(Hyperparameter optimization) & RFECV (Recursive Feature Elimination)\n",
        "\n",
        "\n",
        "# Author\n",
        "### Pradeep Gurav\n",
        "##### https://www.linkedin.com/in/pradeepgurav/\n",
        "\n",
        "#### November 26, 2020\n",
        "\n",
        "##### How to get Pima Diabetes Analysis results > 98%\n",
        "Most of the analysis/models results on Kaggle are around 78%. Piotr's Analysis Notebook which was the highest so far who had achieved 84% accuracy.\n",
        "\n",
        "There are many notebooks describing Data exploration and understanding Pima Diabetes data, so will not cover that part in this report. From the data exploration, many of the features(such as Insulin, SkinThickness etc) had overlapping distribution over the outcomes(Diabetic-/NonDiabetic), so it was going to be hard relying on those features.\n",
        "\n",
        "Tried many methods to improve the accuracy such as:\n",
        "\n",
        "    1. Deleting records with zero values\n",
        "    2. Imputing zero values using KNN, mean values\n",
        "    3. Clipping extreme values or out of range values, bucketing certain features (Age, Pregnancies)\n",
        "    4. Applying LogTransform so as to shift some of the feature's distribution towards Normal. No Good results.\n",
        "    5. Many other imputing methods including my own method (Dense Layer network - regression values)\n",
        "    6. Feature separation, using two separate models using diff features and concatenating the models\n",
        "    7. And also using Optuna to try thousands of combinations of layers, Dense layer units, lr, batch sizes. Optuna is  a fantastic tool.\n",
        "    8. Also used RFECV & PCA to identify most co-relating features\n",
        "    9. What actually contributed the most to the performance is the 'Data Augmentation' method\n",
        "\n",
        "The below code is self explanatory, here is the summary of steps:\n",
        "\n",
        "    1. Splitted original data into 75:25. Saved both as CSVs again. The 25% dataset was not exposed to the model while training.\n",
        "    2. Used 75% dataset(576 records) and added new 76992 records to the original dataset.\n",
        "    3. Used Optuna hyperoptimization to get optimum layers and units.\n",
        "    4. Saved the best model and used the same model once Optuna optimization was completed\n",
        "    5. Used the 25% data kept aside for testing, which have 98% accuracy (same 98% for most classification parameters)\n",
        "    6. This model could lead to accuracy above 99% with a bit more effort\n",
        "       \n",
        "Data files used:\n",
        "\n",
        "    1. Public known data      ../input/pimadiabetescsv/diabetes.csv\n",
        "    2. file with 100 times    ../input/multiples/diabetes75pc_100_times.csv\n",
        "    3. 25% testdata unsued in training    ../input/multiples/diabetes25pc.csv"
      ]
    },
    {
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_kg_hide-output": true,
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2020-11-26T03:01:57.590067Z",
          "iopub.status.busy": "2020-11-26T03:01:57.589199Z",
          "iopub.status.idle": "2020-11-26T03:02:07.126362Z",
          "shell.execute_reply": "2020-11-26T03:02:07.125371Z"
        },
        "papermill": {
          "duration": 9.571883,
          "end_time": "2020-11-26T03:02:07.126542",
          "exception": false,
          "start_time": "2020-11-26T03:01:57.554659",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "F_Qvvry3hV2B"
      },
      "cell_type": "code",
      "source": [
        "#!pip install optuna\n",
        "from __future__ import absolute_import, division, print_function\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Input\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard, ReduceLROnPlateau\n",
        "from keras.backend import clear_session\n",
        "from keras.optimizers import RMSprop, Adam\n",
        "from keras import regularizers\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import seaborn as sns\n",
        "import optuna\n",
        "from optuna.integration import TFKerasPruningCallback\n",
        "\n",
        "from subprocess import check_output\n",
        "import time\n",
        "import warnings\n",
        "\n",
        "import os\n",
        "import sys\n",
        "\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "warnings.simplefilter('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "tS8YIbXPhV2C"
      },
      "cell_type": "code",
      "source": [
        "#This runtime value is used by Optuna to run the permutations required for hyper-parameter optimizations.\n",
        "#The results in this report were achieved over 1 hour run of the Optuna code.\n",
        "runtime = 3600"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-11-26T03:02:07.18418Z",
          "iopub.status.busy": "2020-11-26T03:02:07.183344Z",
          "iopub.status.idle": "2020-11-26T03:02:07.301174Z",
          "shell.execute_reply": "2020-11-26T03:02:07.300479Z"
        },
        "papermill": {
          "duration": 0.148656,
          "end_time": "2020-11-26T03:02:07.301343",
          "exception": false,
          "start_time": "2020-11-26T03:02:07.152687",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "xWmT-Ee-hV2C"
      },
      "cell_type": "code",
      "source": [
        "ori = pd.read_csv(\"../input/multiples/diabetes75pc_100_times.csv\")\n",
        "\n",
        "'''\n",
        "# The below code shows how I split the original data to 75:25 ratio\n",
        "# I wrote a function to fabricate (any number of) new records as \"multiplydata_pcversion\" function\n",
        "\n",
        "ori = pd.read_csv(\"../input/pimadiabetescsv/diabetes.csv\")\n",
        "\n",
        "Train_data = ori[:576]\n",
        "Test_data = ori[576:]\n",
        "Test_data.shape[0]\n",
        "\n",
        "trainfile = \"C://Users//pg//Documents//datascience//case studies//pima//data//diabetes75pc.csv\"\n",
        "testfile = \"C://Users//pg//Documents//datascience//case studies//pima//data//diabetes25pc.csv\"\n",
        "Train_data.to_csv(trainfile, index=False, line_terminator='\\n')\n",
        "#Output ->   ../input/multiples/diabetes75pc_100_times.csv\n",
        "Test_data.to_csv(testfile, index=False, line_terminator='\\n')\n",
        "#Output ->   ../input/multiples/diabetes25pc.csv\n",
        "\n",
        "multiple = 50\n",
        "multiplydata_pcversion(multiple,trainfile)\n",
        "'''\n",
        "print(\"Check the number of records:  \", ori.shape)\n",
        "ori.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6___KOrXhV2D"
      },
      "cell_type": "markdown",
      "source": [
        "### Data Exploration\n",
        "\n",
        "The below heatmap shows correlation among all the features and the Outcome."
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "WifYGW4xhV2E"
      },
      "cell_type": "code",
      "source": [
        "sns.heatmap(ori.corr(),annot=True, cmap = 'YlGnBu')\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(10, 8)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "aII3neXzhV2E"
      },
      "cell_type": "code",
      "source": [
        "ax = sns.violinplot(x='Outcome', y='BloodPressure', data=ori, palette='muted', split=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hjtnRhXqhV2F"
      },
      "cell_type": "markdown",
      "source": [
        "From the above plot we can see that BloodPressure has hardly any effect on the Outcome(Diabetic/NonDiabetic). So we can easily drop similar other features from our model."
      ]
    },
    {
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-11-26T03:02:07.356062Z",
          "iopub.status.busy": "2020-11-26T03:02:07.355196Z",
          "iopub.status.idle": "2020-11-26T03:02:07.410799Z",
          "shell.execute_reply": "2020-11-26T03:02:07.409784Z"
        },
        "papermill": {
          "duration": 0.086397,
          "end_time": "2020-11-26T03:02:07.411004",
          "exception": false,
          "start_time": "2020-11-26T03:02:07.324607",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "PqUUsTUHhV2F"
      },
      "cell_type": "code",
      "source": [
        "pdata = ori.copy(deep=True)\n",
        "feature_names = pdata.columns[:8]\n",
        "X = pdata[feature_names]\n",
        "y = pdata.Outcome\n",
        "\n",
        "# Features chosen based on RFECV result\n",
        "best_features = ['Pregnancies', 'Glucose', 'BMI', 'DiabetesPedigreeFunction']\n",
        "X = StandardScaler().fit_transform(X[best_features])\n",
        "# Splitting  data into training and testing (80% / 20%)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    test_size=0.20\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "execution": {
          "iopub.execute_input": "2020-11-26T03:02:07.581374Z",
          "iopub.status.busy": "2020-11-26T03:02:07.489266Z",
          "iopub.status.idle": "2020-11-26T03:02:11.824346Z",
          "shell.execute_reply": "2020-11-26T03:02:11.823553Z"
        },
        "papermill": {
          "duration": 4.384081,
          "end_time": "2020-11-26T03:02:11.824473",
          "exception": false,
          "start_time": "2020-11-26T03:02:07.440392",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "fEJG9oEFhV2G"
      },
      "cell_type": "code",
      "source": [
        "tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "tf.config.experimental_connect_to_cluster(tpu)\n",
        "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "\n",
        "# instantiate a distribution strategy\n",
        "tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "\n",
        "study_name = \"PIMAFeatureEng\"\n",
        "checkpoint_path = './Pima26Nov.hdf5'\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "# create checkpoint callback\n",
        "cp_callback = keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
        "                                              monitor='val_accuracy',\n",
        "                                              save_weights_only=False,\n",
        "                                              save_best_only=True,\n",
        "                                              verbose=0\n",
        "                                             )\n",
        "\n",
        "with tpu_strategy.scope():\n",
        "    def objective(trial):\n",
        "        # Clear clutter from previous Keras session graphs.\n",
        "        clear_session()\n",
        "\n",
        "        num_epochs = 100\n",
        "            # Create callbacks for early stopping and pruning.\n",
        "        callbacks = [\n",
        "            keras.callbacks.EarlyStopping(patience=3),\n",
        "            TFKerasPruningCallback(trial, \"val_accuracy\"),\n",
        "            cp_callback\n",
        "        ]\n",
        "        model = Sequential()\n",
        "        for i in range(3):\n",
        "            model.add(Dense(int(trial.suggest_discrete_uniform(\n",
        "                'FC_{}_num_hidden_units'.format(i), 16, 80, 4)),\n",
        "                            activation = \"relu\",\n",
        "                            input_dim=4\n",
        "                           )\n",
        "                     )\n",
        "        model.add(Dense(1, activation = 'sigmoid'))\n",
        "        lr = trial.suggest_uniform(\"lr\", 1e-4, 1e-1)\n",
        "        model.compile(loss = 'binary_crossentropy', optimizer = Adam(lr=lr), metrics=['accuracy'])\n",
        "        batch_size = trial.suggest_int('Batch_size', 32, 128, 16)\n",
        "        history = model.fit(X_train,\n",
        "                           y_train,\n",
        "                           validation_data= (X_test, y_test),\n",
        "                           epochs=num_epochs,\n",
        "                           batch_size = batch_size,\n",
        "                           callbacks=callbacks,\n",
        "                           verbose=0\n",
        "                           )\n",
        "        score = model.evaluate(X_test, y_test, verbose=0)\n",
        "        return score[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-11-26T03:02:11.885698Z",
          "iopub.status.busy": "2020-11-26T03:02:11.884785Z",
          "iopub.status.idle": "2020-11-26T03:07:15.270397Z",
          "shell.execute_reply": "2020-11-26T03:07:15.268496Z"
        },
        "papermill": {
          "duration": 303.423335,
          "end_time": "2020-11-26T03:07:15.270536",
          "exception": false,
          "start_time": "2020-11-26T03:02:11.847201",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "T7ALI22ZhV2G"
      },
      "cell_type": "code",
      "source": [
        "tic = time.process_time()\n",
        "#The below line is important to see the logs while Optuna optimization\n",
        "optuna.logging.disable_default_handler()\n",
        "study = optuna.create_study(\n",
        "        sampler=optuna.samplers.TPESampler(\n",
        "            consider_prior=True, prior_weight=1.0,\n",
        "            consider_magic_clip=True, consider_endpoints=False,\n",
        "            n_startup_trials=10, n_ei_candidates=24,\n",
        "            seed=None),\n",
        "        pruner=optuna.pruners.SuccessiveHalvingPruner(\n",
        "            min_resource=2, reduction_factor=4, min_early_stopping_rate=1),\n",
        "        study_name = study_name,\n",
        "        direction=\"maximize\",\n",
        ")\n",
        "\n",
        "#study.optimize(objective, n_trials=100, timeout=600)\n",
        "study.optimize(objective, timeout=runtime)\n",
        "\n",
        "toc = time.process_time()\n",
        "print(\"time taken :  \")\n",
        "print(toc-tic)\n",
        "print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
        "print(\"Best trial number:\", study.best_trial.number)\n",
        "trial = study.best_trial\n",
        "print(\"  Value: {}\".format(trial.value))\n",
        "print(\"  Params: \")\n",
        "for key, value in trial.params.items():\n",
        "    print(\"    {}: {}\".format(key, value))\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-11-26T03:07:15.4079Z",
          "iopub.status.busy": "2020-11-26T03:07:15.40704Z",
          "iopub.status.idle": "2020-11-26T03:07:15.41502Z",
          "shell.execute_reply": "2020-11-26T03:07:15.41427Z"
        },
        "papermill": {
          "duration": 0.079018,
          "end_time": "2020-11-26T03:07:15.415151",
          "exception": false,
          "start_time": "2020-11-26T03:07:15.336133",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "7aJ-4vYrhV2H"
      },
      "cell_type": "code",
      "source": [
        "#ls {checkpoint_path}\n",
        "for dirname, _, filenames in os.walk('./'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-11-26T03:07:15.698478Z",
          "iopub.status.busy": "2020-11-26T03:07:15.697704Z",
          "iopub.status.idle": "2020-11-26T03:07:15.948627Z",
          "shell.execute_reply": "2020-11-26T03:07:15.94795Z"
        },
        "papermill": {
          "duration": 0.323214,
          "end_time": "2020-11-26T03:07:15.948757",
          "exception": false,
          "start_time": "2020-11-26T03:07:15.625543",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "nKDKOjiOhV2H"
      },
      "cell_type": "code",
      "source": [
        "optuna.visualization.plot_intermediate_values(study)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-11-26T03:07:16.393106Z",
          "iopub.status.busy": "2020-11-26T03:07:16.39232Z",
          "iopub.status.idle": "2020-11-26T03:07:16.47672Z",
          "shell.execute_reply": "2020-11-26T03:07:16.476041Z"
        },
        "papermill": {
          "duration": 0.164396,
          "end_time": "2020-11-26T03:07:16.476855",
          "exception": false,
          "start_time": "2020-11-26T03:07:16.312459",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "-Ejb-JHUhV2H"
      },
      "cell_type": "code",
      "source": [
        "optuna.visualization.plot_parallel_coordinate(study)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-11-26T03:07:16.622637Z",
          "iopub.status.busy": "2020-11-26T03:07:16.621721Z",
          "iopub.status.idle": "2020-11-26T03:07:16.817751Z",
          "shell.execute_reply": "2020-11-26T03:07:16.814772Z"
        },
        "papermill": {
          "duration": 0.271377,
          "end_time": "2020-11-26T03:07:16.817893",
          "exception": false,
          "start_time": "2020-11-26T03:07:16.546516",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "YivjsLSehV2H"
      },
      "cell_type": "code",
      "source": [
        "#Load the optimized model which is saved at checkpoint_path\n",
        "print(checkpoint_path)\n",
        "new_model = keras.models.load_model(checkpoint_path)\n",
        "new_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-11-26T03:07:16.99192Z",
          "iopub.status.busy": "2020-11-26T03:07:16.990807Z",
          "iopub.status.idle": "2020-11-26T03:07:19.62255Z",
          "shell.execute_reply": "2020-11-26T03:07:19.623544Z"
        },
        "papermill": {
          "duration": 2.723461,
          "end_time": "2020-11-26T03:07:19.623758",
          "exception": false,
          "start_time": "2020-11-26T03:07:16.900297",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "oL28L5zmhV2H"
      },
      "cell_type": "code",
      "source": [
        "scores = new_model.evaluate(X_test, y_test)\n",
        "py_pred  = new_model.predict(X_test)\n",
        "py_pred = np.where(py_pred > 0.5, 1, 0) #py_pred = py_pred.round()\n",
        "print(\"Accuracy of the training\", scores[1]*100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-11-26T03:07:20.286719Z",
          "iopub.status.busy": "2020-11-26T03:07:20.285663Z",
          "iopub.status.idle": "2020-11-26T03:07:20.64163Z",
          "shell.execute_reply": "2020-11-26T03:07:20.640836Z"
        },
        "papermill": {
          "duration": 0.531794,
          "end_time": "2020-11-26T03:07:20.64177",
          "exception": false,
          "start_time": "2020-11-26T03:07:20.109976",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "5J0pDE7fhV2H"
      },
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test, py_pred)\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sns.set(color_codes =True)\n",
        "sns.set(font_scale=1.5)\n",
        "sns.heatmap(cm, annot=True, fmt='g')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "twVrPhJvhV2H"
      },
      "cell_type": "markdown",
      "source": [
        "Confusion Matrix shows True Positives, True Negatives, False Positives(FP) and False Negatives(FN). 0 FPs and 0 FNs is the ideal outcome."
      ]
    },
    {
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-11-26T03:07:20.956018Z",
          "iopub.status.busy": "2020-11-26T03:07:20.95513Z",
          "iopub.status.idle": "2020-11-26T03:07:20.99879Z",
          "shell.execute_reply": "2020-11-26T03:07:20.997863Z"
        },
        "papermill": {
          "duration": 0.20162,
          "end_time": "2020-11-26T03:07:20.998985",
          "exception": false,
          "start_time": "2020-11-26T03:07:20.797365",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "hjF9aZmdhV2H"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, roc_auc_score, classification_report\n",
        "\n",
        "print('Accuracy: {:.2f}%'.format(accuracy_score(y_test, py_pred) * 100))\n",
        "print('Classification report:\\n\\n', classification_report(y_test, py_pred))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-11-26T03:07:21.322745Z",
          "iopub.status.busy": "2020-11-26T03:07:21.321863Z",
          "iopub.status.idle": "2020-11-26T03:07:21.335815Z",
          "shell.execute_reply": "2020-11-26T03:07:21.336644Z"
        },
        "papermill": {
          "duration": 0.180942,
          "end_time": "2020-11-26T03:07:21.336824",
          "exception": false,
          "start_time": "2020-11-26T03:07:21.155882",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "dCVTiG8nhV2I"
      },
      "cell_type": "code",
      "source": [
        "# Load the test data which was kept aside in the beginning\n",
        "test = pd.read_csv(\"../input/multiples/diabetes25pc.csv\")\n",
        "best_features = ['Pregnancies', 'Glucose', 'BMI', 'DiabetesPedigreeFunction']\n",
        "X1 = StandardScaler().fit_transform(test[best_features])\n",
        "y1 = test.Outcome"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-11-26T03:07:21.652375Z",
          "iopub.status.busy": "2020-11-26T03:07:21.651293Z",
          "iopub.status.idle": "2020-11-26T03:07:21.718454Z",
          "shell.execute_reply": "2020-11-26T03:07:21.717748Z"
        },
        "papermill": {
          "duration": 0.226244,
          "end_time": "2020-11-26T03:07:21.718584",
          "exception": false,
          "start_time": "2020-11-26T03:07:21.49234",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "2IUMTnEhhV2I"
      },
      "cell_type": "code",
      "source": [
        "py_pred1  = new_model.predict(X1)\n",
        "py_pred1 = np.where(py_pred1 > 0.5, 1, 0) #py_pred = py_pred.round()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-11-26T03:07:22.031955Z",
          "iopub.status.busy": "2020-11-26T03:07:22.031041Z",
          "iopub.status.idle": "2020-11-26T03:07:22.24916Z",
          "shell.execute_reply": "2020-11-26T03:07:22.24838Z"
        },
        "papermill": {
          "duration": 0.378799,
          "end_time": "2020-11-26T03:07:22.249311",
          "exception": false,
          "start_time": "2020-11-26T03:07:21.870512",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "uBGvX5PjhV2I"
      },
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y1, py_pred1)\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sns.set(color_codes =True)\n",
        "sns.set(font_scale=1.5)\n",
        "sns.heatmap(cm, annot=True, fmt='g')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-11-26T03:07:22.564591Z",
          "iopub.status.busy": "2020-11-26T03:07:22.563554Z",
          "iopub.status.idle": "2020-11-26T03:07:22.581946Z",
          "shell.execute_reply": "2020-11-26T03:07:22.581346Z"
        },
        "papermill": {
          "duration": 0.178954,
          "end_time": "2020-11-26T03:07:22.582076",
          "exception": false,
          "start_time": "2020-11-26T03:07:22.403122",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "1SgJaG5nhV2I"
      },
      "cell_type": "code",
      "source": [
        "print('Accuracy: {:.2f}%'.format(accuracy_score(y1, py_pred1) * 100))\n",
        "print('Classification report:\\n\\n', classification_report(y1, py_pred1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vnJVIeMshV2I"
      },
      "cell_type": "markdown",
      "source": [
        "### Discussion on Results achieved\n",
        "\n",
        "1. The report describes various methods tried to optimize the results\n",
        "2. It provides a framework which uses various tools and techniques to solve similar problems\n",
        "3. There is significant jump in accuracy improvement from 84% to 98%"
      ]
    },
    {
      "metadata": {
        "id": "k-1Gz06bhV2I"
      },
      "cell_type": "markdown",
      "source": [
        "    \n",
        "### References /Acknowledgements\n",
        "\n",
        "####  1. Notebook by Piotr Tynecki on Pima Dataset:->    https://www.kaggle.com/ptynecki/pima-indians-diabetes-prediction-with-lr-84\n",
        "\n",
        "\n",
        "\n",
        "####  2. Optuna - used for hyperparameter optimization:->    https://optuna.org/\n",
        "\n",
        "\n",
        "\n",
        "####  3. Kaggle - Thanks for providing this fantastic platform and allowing to use GPUs/TPUs"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "JrsBS0hVhV2J"
      },
      "cell_type": "code",
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "Pima Diabetes Dataset Analysis 98% Accuracy",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}